
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Heart Attack Prediction &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/heart_final';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Intro &amp; Links" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="My sample book - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Intro & Links
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Heart Attack Prediction</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fnotebooks/heart_final.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/heart_final.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Heart Attack Prediction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="heart-attack-prediction">
<h1>Heart Attack Prediction<a class="headerlink" href="#heart-attack-prediction" title="Link to this heading">#</a></h1>
<p>Create a normalized database (3NF).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="c1"># Load the dataset</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;C:\UB ESDS\SEM 1\Python\heart_data.csv&#39;</span>  <span class="c1"># Use a raw string (r&#39;&#39;) for Windows file paths</span>
<span class="n">heart_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>

<span class="c1"># Connect to SQLite database (it will create the file if it doesn&#39;t exist)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;heart_attack_prediction.db&quot;</span><span class="p">)</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

<span class="c1"># Create Patients table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS Patients (</span>
<span class="s2">    PatientID INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s2">    Age INTEGER NOT NULL,</span>
<span class="s2">    Sex INTEGER NOT NULL</span>
<span class="s2">);</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Create HealthMetrics table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS HealthMetrics (</span>
<span class="s2">    MetricID INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s2">    PatientID INTEGER NOT NULL,</span>
<span class="s2">    Trestbps INTEGER NOT NULL,</span>
<span class="s2">    Chol INTEGER NOT NULL,</span>
<span class="s2">    Thalach INTEGER NOT NULL,</span>
<span class="s2">    Oldpeak REAL NOT NULL,</span>
<span class="s2">    FOREIGN KEY (PatientID) REFERENCES Patients(PatientID)</span>
<span class="s2">);</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Create HeartAttackRisk table</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">CREATE TABLE IF NOT EXISTS HeartAttackRisk (</span>
<span class="s2">    RiskID INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s2">    PatientID INTEGER NOT NULL,</span>
<span class="s2">    Cp INTEGER NOT NULL,</span>
<span class="s2">    Target INTEGER NOT NULL,</span>
<span class="s2">    FOREIGN KEY (PatientID) REFERENCES Patients(PatientID)</span>
<span class="s2">);</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Populate the Patients table</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">heart_data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO Patients (Age, Sex)</span>
<span class="s2">    VALUES (?, ?);</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]))</span>

<span class="c1"># Fetch PatientIDs to maintain relationships</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT PatientID FROM Patients&quot;</span><span class="p">)</span>
<span class="n">patient_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()]</span>

<span class="c1"># Populate the HealthMetrics table</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">heart_data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO HealthMetrics (PatientID, Trestbps, Chol, Thalach, Oldpeak)</span>
<span class="s2">    VALUES (?, ?, ?, ?, ?);</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="p">(</span>
        <span class="n">patient_ids</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
        <span class="n">row</span><span class="p">[</span><span class="s1">&#39;trestbps&#39;</span><span class="p">],</span>
        <span class="n">row</span><span class="p">[</span><span class="s1">&#39;chol&#39;</span><span class="p">],</span>
        <span class="n">row</span><span class="p">[</span><span class="s1">&#39;thalach&#39;</span><span class="p">],</span>
        <span class="n">row</span><span class="p">[</span><span class="s1">&#39;oldpeak&#39;</span><span class="p">]</span>
    <span class="p">))</span>

<span class="c1"># Populate the HeartAttackRisk table</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">heart_data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    INSERT INTO HeartAttackRisk (PatientID, Cp, Target)</span>
<span class="s2">    VALUES (?, ?, ?);</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span> <span class="p">(</span>
        <span class="n">patient_ids</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
        <span class="n">row</span><span class="p">[</span><span class="s1">&#39;cp&#39;</span><span class="p">],</span>
        <span class="n">row</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
    <span class="p">))</span>

<span class="c1"># Commit and close the database connection</span>
<span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Database and data insertion completed successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Database and data insertion completed successfully!
</pre></div>
</div>
</div>
</div>
<p>Write SQL join statement to fetch data from the database and into Pandas DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="c1"># Connect to the SQLite database</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;heart_attack_prediction.db&quot;</span><span class="p">)</span>

<span class="c1"># SQL query to join the tables and fetch data</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">SELECT </span>
<span class="s2">    p.PatientID, </span>
<span class="s2">    p.Age, </span>
<span class="s2">    p.Sex, </span>
<span class="s2">    hm.Trestbps, </span>
<span class="s2">    hm.Chol, </span>
<span class="s2">    hm.Thalach, </span>
<span class="s2">    hm.Oldpeak, </span>
<span class="s2">    har.Cp, </span>
<span class="s2">    har.Target</span>
<span class="s2">FROM </span>
<span class="s2">    Patients AS p</span>
<span class="s2">JOIN </span>
<span class="s2">    HealthMetrics AS hm </span>
<span class="s2">ON </span>
<span class="s2">    p.PatientID = hm.PatientID</span>
<span class="s2">JOIN </span>
<span class="s2">    HeartAttackRisk AS har </span>
<span class="s2">ON </span>
<span class="s2">    p.PatientID = har.PatientID;</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># Execute the query and load the data into a Pandas DataFrame</span>
<span class="n">joined_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql_query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>

<span class="c1"># Close the database connection</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Display the DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   PatientID  Age  Sex  Trestbps  Chol  Thalach  Oldpeak  Cp  Target
0          1   63    1       145   233      150      2.3   3       1
1          1   63    1       145   233      150      2.3   3       1
2          1   63    1       145   233      150      2.3   3       1
3          1   63    1       145   233      150      2.3   3       1
4          1   63    1       145   233      150      2.3   3       1
</pre></div>
</div>
</div>
</div>
<p>Explore the data to determine if you need to stratify it by some attribute when doing train/test split. Perform the train/test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load the dataset</span>
<span class="n">joined_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;C:/UB ESDS/SEM 1/Python/heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Data exploration</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset Information:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Summary Statistics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Checking for missing values:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Target Distribution:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>

<span class="c1"># Visualize the distribution of the target variable</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">joined_data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Target Variable&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Visualizing correlations</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Correlation Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Features and target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>  <span class="c1"># Features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">joined_data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>  <span class="c1"># Target</span>

<span class="c1"># Train-test split with stratification</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># Checking the distribution in the train and test sets</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train Target Distribution:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Target Distribution:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># Print train and test sizes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train set size: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test set size: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;seaborn&#39;
</pre></div>
</div>
</div>
</div>
<p>Explore the data using yprofile and correlation matrix. Make observations about features, distributions, capped values, and missing values. Create a list of data cleanup tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">ydata</span><span class="o">-</span><span class="n">profiling</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: ydata-profiling in c:\anaconda_navigator\lib\site-packages (4.12.1)
Requirement already satisfied: scipy&lt;1.14,&gt;=1.4.1 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (1.13.1)
Requirement already satisfied: pandas!=1.4.0,&lt;3,&gt;1.1 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (2.2.2)
Requirement already satisfied: matplotlib&lt;3.10,&gt;=3.5 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (3.8.4)
Requirement already satisfied: pydantic&gt;=2 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (2.5.3)
Requirement already satisfied: PyYAML&lt;6.1,&gt;=5.0.0 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (6.0.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=2.11.1 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (3.1.4)
Requirement already satisfied: visions&lt;0.7.7,&gt;=0.7.5 in c:\anaconda_navigator\lib\site-packages (from visions[type_image_path]&lt;0.7.7,&gt;=0.7.5-&gt;ydata-profiling) (0.7.6)
Requirement already satisfied: numpy&lt;2.2,&gt;=1.16.0 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (1.26.4)
Requirement already satisfied: htmlmin==0.1.12 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (0.1.12)
Requirement already satisfied: phik&lt;0.13,&gt;=0.11.1 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (0.12.4)
Requirement already satisfied: requests&lt;3,&gt;=2.24.0 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (2.32.2)
Requirement already satisfied: tqdm&lt;5,&gt;=4.48.2 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (4.66.4)
Requirement already satisfied: seaborn&lt;0.14,&gt;=0.10.1 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (0.13.2)
Requirement already satisfied: multimethod&lt;2,&gt;=1.4 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (1.12)
Requirement already satisfied: statsmodels&lt;1,&gt;=0.13.2 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (0.14.2)
Requirement already satisfied: typeguard&lt;5,&gt;=3 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (4.4.1)
Requirement already satisfied: imagehash==4.3.1 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (4.3.1)
Requirement already satisfied: wordcloud&gt;=1.9.3 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (1.9.4)
Collecting dacite&gt;=1.8 (from ydata-profiling)
  Using cached dacite-1.8.1-py3-none-any.whl.metadata (15 kB)
Requirement already satisfied: numba&lt;1,&gt;=0.56.0 in c:\anaconda_navigator\lib\site-packages (from ydata-profiling) (0.59.1)
Requirement already satisfied: PyWavelets in c:\anaconda_navigator\lib\site-packages (from imagehash==4.3.1-&gt;ydata-profiling) (1.5.0)
Requirement already satisfied: pillow in c:\anaconda_navigator\lib\site-packages (from imagehash==4.3.1-&gt;ydata-profiling) (10.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in c:\anaconda_navigator\lib\site-packages (from jinja2&lt;3.2,&gt;=2.11.1-&gt;ydata-profiling) (2.1.3)
Requirement already satisfied: contourpy&gt;=1.0.1 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (1.2.0)
Requirement already satisfied: cycler&gt;=0.10 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (4.51.0)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (1.4.4)
Requirement already satisfied: packaging&gt;=20.0 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (23.2)
Requirement already satisfied: pyparsing&gt;=2.3.1 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.7 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;3.10,&gt;=3.5-&gt;ydata-profiling) (2.9.0.post0)
Requirement already satisfied: llvmlite&lt;0.43,&gt;=0.42.0dev0 in c:\anaconda_navigator\lib\site-packages (from numba&lt;1,&gt;=0.56.0-&gt;ydata-profiling) (0.42.0)
Requirement already satisfied: pytz&gt;=2020.1 in c:\anaconda_navigator\lib\site-packages (from pandas!=1.4.0,&lt;3,&gt;1.1-&gt;ydata-profiling) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in c:\anaconda_navigator\lib\site-packages (from pandas!=1.4.0,&lt;3,&gt;1.1-&gt;ydata-profiling) (2023.3)
Requirement already satisfied: joblib&gt;=0.14.1 in c:\anaconda_navigator\lib\site-packages (from phik&lt;0.13,&gt;=0.11.1-&gt;ydata-profiling) (1.4.2)
Requirement already satisfied: annotated-types&gt;=0.4.0 in c:\anaconda_navigator\lib\site-packages (from pydantic&gt;=2-&gt;ydata-profiling) (0.6.0)
Requirement already satisfied: pydantic-core==2.14.6 in c:\anaconda_navigator\lib\site-packages (from pydantic&gt;=2-&gt;ydata-profiling) (2.14.6)
Requirement already satisfied: typing-extensions&gt;=4.6.1 in c:\anaconda_navigator\lib\site-packages (from pydantic&gt;=2-&gt;ydata-profiling) (4.11.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\anaconda_navigator\lib\site-packages (from requests&lt;3,&gt;=2.24.0-&gt;ydata-profiling) (2.0.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in c:\anaconda_navigator\lib\site-packages (from requests&lt;3,&gt;=2.24.0-&gt;ydata-profiling) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\anaconda_navigator\lib\site-packages (from requests&lt;3,&gt;=2.24.0-&gt;ydata-profiling) (2.2.2)
Requirement already satisfied: certifi&gt;=2017.4.17 in c:\anaconda_navigator\lib\site-packages (from requests&lt;3,&gt;=2.24.0-&gt;ydata-profiling) (2024.7.4)
Requirement already satisfied: patsy&gt;=0.5.6 in c:\anaconda_navigator\lib\site-packages (from statsmodels&lt;1,&gt;=0.13.2-&gt;ydata-profiling) (0.5.6)
Requirement already satisfied: colorama in c:\anaconda_navigator\lib\site-packages (from tqdm&lt;5,&gt;=4.48.2-&gt;ydata-profiling) (0.4.6)
Requirement already satisfied: attrs&gt;=19.3.0 in c:\anaconda_navigator\lib\site-packages (from visions&lt;0.7.7,&gt;=0.7.5-&gt;visions[type_image_path]&lt;0.7.7,&gt;=0.7.5-&gt;ydata-profiling) (23.1.0)
Requirement already satisfied: networkx&gt;=2.4 in c:\anaconda_navigator\lib\site-packages (from visions&lt;0.7.7,&gt;=0.7.5-&gt;visions[type_image_path]&lt;0.7.7,&gt;=0.7.5-&gt;ydata-profiling) (3.2.1)
Requirement already satisfied: six in c:\anaconda_navigator\lib\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels&lt;1,&gt;=0.13.2-&gt;ydata-profiling) (1.16.0)
Using cached dacite-1.8.1-py3-none-any.whl (14 kB)
Installing collected packages: dacite
  Attempting uninstall: dacite
    Found existing installation: dacite 1.6.0
    Uninstalling dacite-1.6.0:
      Successfully uninstalled dacite-1.6.0
Successfully installed dacite-1.8.1
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
dagshub 0.4.0 requires dacite~=1.6.0, but you have dacite 1.8.1 which is incompatible.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ydata_profiling</span> <span class="kn">import</span> <span class="n">ProfileReport</span>  <span class="c1"># Requires &#39;pip install ydata-profiling&#39;</span>

<span class="c1"># Load the dataset</span>
<span class="n">joined_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;C:/UB ESDS/SEM 1/Python/heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Generate a profile report for the dataset</span>
<span class="n">profile</span> <span class="o">=</span> <span class="n">ProfileReport</span><span class="p">(</span><span class="n">joined_data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Heart Data Profiling Report&quot;</span><span class="p">,</span> <span class="n">explorative</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">profile</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s2">&quot;heart_data_profile.html&quot;</span><span class="p">)</span>  <span class="c1"># Saves a detailed report as an HTML file</span>

<span class="c1"># Display a summary of missing values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Values Summary:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="c1"># Visualize the correlation matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;coolwarm&quot;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Identify cleanup tasks</span>
<span class="n">cleanup_tasks</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Check for missing values</span>
<span class="k">if</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">cleanup_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;Handle missing values (imputation or removal).&quot;</span><span class="p">)</span>

<span class="c1"># Check for capped values (e.g., features with max values that seem unusual)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.99</span><span class="p">):</span>
        <span class="n">cleanup_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Investigate potential outliers in &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span>

<span class="c1"># Add notes for any strongly correlated features (arbitrarily set at &gt; 0.75)</span>
<span class="n">correlated_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">corr_value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span>
    <span class="k">for</span> <span class="n">col2</span><span class="p">,</span> <span class="n">corr_value</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>  <span class="c1"># Use `items()` instead of `iteritems()`</span>
    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">corr_value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.75</span> <span class="ow">and</span> <span class="n">col1</span> <span class="o">!=</span> <span class="n">col2</span>
<span class="p">]</span>
<span class="k">if</span> <span class="n">correlated_features</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">correlated_features</span><span class="p">:</span>
        <span class="n">cleanup_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Consider dropping or transforming one of the highly correlated features: </span><span class="si">{</span><span class="n">feat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">feat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> (corr=</span><span class="si">{</span><span class="n">feat</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

<span class="c1"># List cleanup tasks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Cleanup Tasks:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">cleanup_tasks</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "165ac061fd6844bdbabec2c6e2c21ec1", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "d030af5fdaf34b17b18118c6be6b8587", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "a8104026b07a4ea09687457eb34580f3", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "469b6ff848244b04a395340e3bb11160", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing Values Summary:
age         0
sex         0
cp          0
trestbps    0
chol        0
fbs         0
restecg     0
thalach     0
exang       0
oldpeak     0
slope       0
ca          0
thal        0
target      0
dtype: int64
</pre></div>
</div>
<img alt="../_images/5ba4844c1e21b0dd19d8dfcdd2765a4dcf5262f9a79e14a06537e920b5eaec26.png" src="../_images/5ba4844c1e21b0dd19d8dfcdd2765a4dcf5262f9a79e14a06537e920b5eaec26.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data Cleanup Tasks:
- Investigate potential outliers in &#39;age&#39;.
- Investigate potential outliers in &#39;trestbps&#39;.
- Investigate potential outliers in &#39;chol&#39;.
- Investigate potential outliers in &#39;restecg&#39;.
- Investigate potential outliers in &#39;thalach&#39;.
- Investigate potential outliers in &#39;oldpeak&#39;.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load the dataset</span>
<span class="n">joined_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;C:/UB ESDS/SEM 1/Python/heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># 1. Handle Missing Values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Values Before Cleanup:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="c1"># Fill missing values (example: using median for numerical columns)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">]:</span>
            <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Values After Cleanup:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="c1"># 2. Investigate and Handle Outliers</span>
<span class="c1"># Using IQR to cap outliers</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">Q1</span> <span class="o">=</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
    <span class="n">Q3</span> <span class="o">=</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>
    <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
    <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
    <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">joined_data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="n">lower_bound</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">upper_bound</span><span class="p">)</span>

<span class="c1"># 3. Handle Highly Correlated Features</span>
<span class="c1"># Drop one of the highly correlated features (arbitrarily set threshold &gt; 0.75)</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">joined_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">high_corr_pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span>
    <span class="k">for</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span>
    <span class="k">if</span> <span class="n">col1</span> <span class="o">!=</span> <span class="n">col2</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">[</span><span class="n">col1</span><span class="p">][</span><span class="n">col2</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.75</span>
<span class="p">]</span>

<span class="c1"># Drop duplicate highly correlated features (keeping one)</span>
<span class="n">features_to_drop</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <span class="n">col1</span><span class="p">,</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">high_corr_pairs</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">col1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">features_to_drop</span> <span class="ow">and</span> <span class="n">col2</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">features_to_drop</span><span class="p">:</span>
        <span class="n">features_to_drop</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">col2</span><span class="p">)</span>

<span class="n">joined_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">features_to_drop</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Final Dataset Summary</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final Dataset After Cleanup:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_data</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>

<span class="c1"># Save the cleaned dataset</span>
<span class="n">joined_data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cleaned dataset saved as &#39;cleaned_heart_data.csv&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing Values Before Cleanup:
age         0
sex         0
cp          0
trestbps    0
chol        0
fbs         0
restecg     0
thalach     0
exang       0
oldpeak     0
slope       0
ca          0
thal        0
target      0
dtype: int64
Missing Values After Cleanup:
age         0
sex         0
cp          0
trestbps    0
chol        0
fbs         0
restecg     0
thalach     0
exang       0
oldpeak     0
slope       0
ca          0
thal        0
target      0
dtype: int64
Final Dataset After Cleanup:
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 303 entries, 0 to 302
Data columns (total 14 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   age       303 non-null    int64  
 1   sex       303 non-null    int64  
 2   cp        303 non-null    int64  
 3   trestbps  303 non-null    int64  
 4   chol      303 non-null    float64
 5   fbs       303 non-null    int64  
 6   restecg   303 non-null    int64  
 7   thalach   303 non-null    float64
 8   exang     303 non-null    int64  
 9   oldpeak   303 non-null    float64
 10  slope     303 non-null    int64  
 11  ca        303 non-null    float64
 12  thal      303 non-null    float64
 13  target    303 non-null    int64  
dtypes: float64(5), int64(9)
memory usage: 33.3 KB
None
Cleaned dataset saved as &#39;cleaned_heart_data.csv&#39;
</pre></div>
</div>
</div>
</div>
<p>Experiment #1: Create a pipeline for preprocessing (StandardScaler, MinMaxScaler, LogTransformation, OneHotEncoding) and Logistic Regression. Log F1-score/(TP,TN,FN,FP)  in MLFlow on DagsHub. – Cross validation 3/10 folds. Results—mean/std of CV results and results on the whole training data – add in parameter hyper tuning</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">mlflow</span> <span class="n">dagshub</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span> <span class="n">numpy</span> <span class="n">pandas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: mlflow in c:\anaconda_navigator\lib\site-packages (2.19.0)
Requirement already satisfied: dagshub in c:\anaconda_navigator\lib\site-packages (0.4.0)
Requirement already satisfied: scikit-learn in c:\anaconda_navigator\lib\site-packages (1.4.2)
Requirement already satisfied: numpy in c:\anaconda_navigator\lib\site-packages (1.26.4)
Requirement already satisfied: pandas in c:\anaconda_navigator\lib\site-packages (2.2.2)
Requirement already satisfied: mlflow-skinny==2.19.0 in c:\anaconda_navigator\lib\site-packages (from mlflow) (2.19.0)
Requirement already satisfied: Flask&lt;4 in c:\anaconda_navigator\lib\site-packages (from mlflow) (3.0.3)
Requirement already satisfied: Jinja2&lt;4,&gt;=3.0 in c:\anaconda_navigator\lib\site-packages (from mlflow) (3.1.4)
Requirement already satisfied: alembic!=1.10.0,&lt;2 in c:\anaconda_navigator\lib\site-packages (from mlflow) (1.14.0)
Requirement already satisfied: docker&lt;8,&gt;=4.0.0 in c:\anaconda_navigator\lib\site-packages (from mlflow) (7.1.0)
Requirement already satisfied: graphene&lt;4 in c:\anaconda_navigator\lib\site-packages (from mlflow) (3.4.3)
Requirement already satisfied: markdown&lt;4,&gt;=3.3 in c:\anaconda_navigator\lib\site-packages (from mlflow) (3.4.1)
Requirement already satisfied: matplotlib&lt;4 in c:\anaconda_navigator\lib\site-packages (from mlflow) (3.8.4)
Requirement already satisfied: pyarrow&lt;19,&gt;=4.0.0 in c:\anaconda_navigator\lib\site-packages (from mlflow) (14.0.2)
Requirement already satisfied: scipy&lt;2 in c:\anaconda_navigator\lib\site-packages (from mlflow) (1.13.1)
Requirement already satisfied: sqlalchemy&lt;3,&gt;=1.4.0 in c:\anaconda_navigator\lib\site-packages (from mlflow) (2.0.30)
Requirement already satisfied: waitress&lt;4 in c:\anaconda_navigator\lib\site-packages (from mlflow) (3.0.2)
Requirement already satisfied: cachetools&lt;6,&gt;=5.0.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (5.3.3)
Requirement already satisfied: click&lt;9,&gt;=7.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (8.1.7)
Requirement already satisfied: cloudpickle&lt;4 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (2.2.1)
Requirement already satisfied: databricks-sdk&lt;1,&gt;=0.20.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (0.40.0)
Requirement already satisfied: gitpython&lt;4,&gt;=3.1.9 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (3.1.37)
Requirement already satisfied: importlib_metadata!=4.7.0,&lt;9,&gt;=3.7.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (7.0.1)
Requirement already satisfied: opentelemetry-api&lt;3,&gt;=1.9.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (1.29.0)
Requirement already satisfied: opentelemetry-sdk&lt;3,&gt;=1.9.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (1.29.0)
Requirement already satisfied: packaging&lt;25 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (23.2)
Requirement already satisfied: protobuf&lt;6,&gt;=3.12.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (3.20.3)
Requirement already satisfied: pyyaml&lt;7,&gt;=5.1 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (6.0.1)
Requirement already satisfied: requests&lt;3,&gt;=2.17.3 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (2.32.2)
Requirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in c:\anaconda_navigator\lib\site-packages (from mlflow-skinny==2.19.0-&gt;mlflow) (0.5.3)
Requirement already satisfied: appdirs&gt;=1.4.4 in c:\anaconda_navigator\lib\site-packages (from dagshub) (1.4.4)
Requirement already satisfied: httpx&gt;=0.23.0 in c:\anaconda_navigator\lib\site-packages (from dagshub) (0.27.0)
Requirement already satisfied: rich&gt;=13.1.0 in c:\anaconda_navigator\lib\site-packages (from dagshub) (13.3.5)
Requirement already satisfied: dacite~=1.6.0 in c:\anaconda_navigator\lib\site-packages (from dagshub) (1.6.0)
Requirement already satisfied: tenacity&gt;=8.2.2 in c:\anaconda_navigator\lib\site-packages (from dagshub) (8.2.2)
Requirement already satisfied: gql[requests] in c:\anaconda_navigator\lib\site-packages (from dagshub) (3.5.0)
Requirement already satisfied: dataclasses-json in c:\anaconda_navigator\lib\site-packages (from dagshub) (0.6.7)
Requirement already satisfied: treelib&gt;=1.6.4 in c:\anaconda_navigator\lib\site-packages (from dagshub) (1.7.0)
Requirement already satisfied: pathvalidate&gt;=3.0.0 in c:\anaconda_navigator\lib\site-packages (from dagshub) (3.2.1)
Requirement already satisfied: python-dateutil in c:\anaconda_navigator\lib\site-packages (from dagshub) (2.9.0.post0)
Requirement already satisfied: boto3 in c:\anaconda_navigator\lib\site-packages (from dagshub) (1.35.85)
Requirement already satisfied: dagshub-annotation-converter&gt;=0.1.0 in c:\anaconda_navigator\lib\site-packages (from dagshub) (0.1.2)
Requirement already satisfied: joblib&gt;=1.2.0 in c:\anaconda_navigator\lib\site-packages (from scikit-learn) (1.4.2)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in c:\anaconda_navigator\lib\site-packages (from scikit-learn) (2.2.0)
Requirement already satisfied: pytz&gt;=2020.1 in c:\anaconda_navigator\lib\site-packages (from pandas) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in c:\anaconda_navigator\lib\site-packages (from pandas) (2023.3)
Requirement already satisfied: Mako in c:\anaconda_navigator\lib\site-packages (from alembic!=1.10.0,&lt;2-&gt;mlflow) (1.3.8)
Requirement already satisfied: typing-extensions&gt;=4 in c:\anaconda_navigator\lib\site-packages (from alembic!=1.10.0,&lt;2-&gt;mlflow) (4.11.0)
Requirement already satisfied: colorama in c:\anaconda_navigator\lib\site-packages (from click&lt;9,&gt;=7.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.4.6)
Requirement already satisfied: lxml in c:\anaconda_navigator\lib\site-packages (from dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (5.2.1)
Requirement already satisfied: pillow in c:\anaconda_navigator\lib\site-packages (from dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (10.3.0)
Requirement already satisfied: pydantic&gt;=2.0.0 in c:\anaconda_navigator\lib\site-packages (from dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (2.5.3)
Requirement already satisfied: pywin32&gt;=304 in c:\anaconda_navigator\lib\site-packages (from docker&lt;8,&gt;=4.0.0-&gt;mlflow) (305.1)
Requirement already satisfied: urllib3&gt;=1.26.0 in c:\anaconda_navigator\lib\site-packages (from docker&lt;8,&gt;=4.0.0-&gt;mlflow) (2.2.2)
Requirement already satisfied: Werkzeug&gt;=3.0.0 in c:\anaconda_navigator\lib\site-packages (from Flask&lt;4-&gt;mlflow) (3.0.3)
Requirement already satisfied: itsdangerous&gt;=2.1.2 in c:\anaconda_navigator\lib\site-packages (from Flask&lt;4-&gt;mlflow) (2.2.0)
Requirement already satisfied: blinker&gt;=1.6.2 in c:\anaconda_navigator\lib\site-packages (from Flask&lt;4-&gt;mlflow) (1.6.2)
Requirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in c:\anaconda_navigator\lib\site-packages (from gitpython&lt;4,&gt;=3.1.9-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (4.0.7)
Requirement already satisfied: graphql-core&lt;3.3,&gt;=3.1 in c:\anaconda_navigator\lib\site-packages (from graphene&lt;4-&gt;mlflow) (3.2.5)
Requirement already satisfied: graphql-relay&lt;3.3,&gt;=3.1 in c:\anaconda_navigator\lib\site-packages (from graphene&lt;4-&gt;mlflow) (3.2.0)
Requirement already satisfied: anyio in c:\anaconda_navigator\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (4.2.0)
Requirement already satisfied: certifi in c:\anaconda_navigator\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (2024.7.4)
Requirement already satisfied: httpcore==1.* in c:\anaconda_navigator\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (1.0.2)
Requirement already satisfied: idna in c:\anaconda_navigator\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (3.7)
Requirement already satisfied: sniffio in c:\anaconda_navigator\lib\site-packages (from httpx&gt;=0.23.0-&gt;dagshub) (1.3.0)
Requirement already satisfied: h11&lt;0.15,&gt;=0.13 in c:\anaconda_navigator\lib\site-packages (from httpcore==1.*-&gt;httpx&gt;=0.23.0-&gt;dagshub) (0.14.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in c:\anaconda_navigator\lib\site-packages (from Jinja2&lt;4,&gt;=3.0-&gt;mlflow) (2.1.3)
Requirement already satisfied: contourpy&gt;=1.0.1 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (1.2.0)
Requirement already satisfied: cycler&gt;=0.10 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (4.51.0)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.3.1 in c:\anaconda_navigator\lib\site-packages (from matplotlib&lt;4-&gt;mlflow) (3.0.9)
Requirement already satisfied: six&gt;=1.5 in c:\anaconda_navigator\lib\site-packages (from python-dateutil-&gt;dagshub) (1.16.0)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in c:\anaconda_navigator\lib\site-packages (from rich&gt;=13.1.0-&gt;dagshub) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in c:\anaconda_navigator\lib\site-packages (from rich&gt;=13.1.0-&gt;dagshub) (2.15.1)
Requirement already satisfied: greenlet!=0.4.17 in c:\anaconda_navigator\lib\site-packages (from sqlalchemy&lt;3,&gt;=1.4.0-&gt;mlflow) (3.0.1)
Requirement already satisfied: botocore&lt;1.36.0,&gt;=1.35.85 in c:\anaconda_navigator\lib\site-packages (from boto3-&gt;dagshub) (1.35.85)
Requirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in c:\anaconda_navigator\lib\site-packages (from boto3-&gt;dagshub) (1.0.1)
Requirement already satisfied: s3transfer&lt;0.11.0,&gt;=0.10.0 in c:\anaconda_navigator\lib\site-packages (from boto3-&gt;dagshub) (0.10.4)
Requirement already satisfied: marshmallow&lt;4.0.0,&gt;=3.18.0 in c:\anaconda_navigator\lib\site-packages (from dataclasses-json-&gt;dagshub) (3.23.2)
Requirement already satisfied: typing-inspect&lt;1,&gt;=0.4.0 in c:\anaconda_navigator\lib\site-packages (from dataclasses-json-&gt;dagshub) (0.9.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.6 in c:\anaconda_navigator\lib\site-packages (from gql[requests]-&gt;dagshub) (1.9.3)
Requirement already satisfied: backoff&lt;3.0,&gt;=1.11.1 in c:\anaconda_navigator\lib\site-packages (from gql[requests]-&gt;dagshub) (2.2.1)
Requirement already satisfied: requests-toolbelt&lt;2,&gt;=1.0.0 in c:\anaconda_navigator\lib\site-packages (from gql[requests]-&gt;dagshub) (1.0.0)
Requirement already satisfied: google-auth~=2.0 in c:\anaconda_navigator\lib\site-packages (from databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (2.37.0)
Requirement already satisfied: smmap&lt;5,&gt;=3.0.1 in c:\anaconda_navigator\lib\site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=3.1.9-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (4.0.0)
Requirement already satisfied: zipp&gt;=0.5 in c:\anaconda_navigator\lib\site-packages (from importlib_metadata!=4.7.0,&lt;9,&gt;=3.7.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (3.17.0)
Requirement already satisfied: mdurl~=0.1 in c:\anaconda_navigator\lib\site-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich&gt;=13.1.0-&gt;dagshub) (0.1.0)
Requirement already satisfied: deprecated&gt;=1.2.6 in c:\anaconda_navigator\lib\site-packages (from opentelemetry-api&lt;3,&gt;=1.9.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (1.2.15)
Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\anaconda_navigator\lib\site-packages (from opentelemetry-sdk&lt;3,&gt;=1.9.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.50b0)
Requirement already satisfied: annotated-types&gt;=0.4.0 in c:\anaconda_navigator\lib\site-packages (from pydantic&gt;=2.0.0-&gt;dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (0.6.0)
Requirement already satisfied: pydantic-core==2.14.6 in c:\anaconda_navigator\lib\site-packages (from pydantic&gt;=2.0.0-&gt;dagshub-annotation-converter&gt;=0.1.0-&gt;dagshub) (2.14.6)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\anaconda_navigator\lib\site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (2.0.4)
Requirement already satisfied: mypy-extensions&gt;=0.3.0 in c:\anaconda_navigator\lib\site-packages (from typing-inspect&lt;1,&gt;=0.4.0-&gt;dataclasses-json-&gt;dagshub) (1.0.0)
Requirement already satisfied: multidict&gt;=4.0 in c:\anaconda_navigator\lib\site-packages (from yarl&lt;2.0,&gt;=1.6-&gt;gql[requests]-&gt;dagshub) (6.0.4)
Requirement already satisfied: wrapt&lt;2,&gt;=1.10 in c:\anaconda_navigator\lib\site-packages (from deprecated&gt;=1.2.6-&gt;opentelemetry-api&lt;3,&gt;=1.9.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (1.14.1)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in c:\anaconda_navigator\lib\site-packages (from google-auth~=2.0-&gt;databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in c:\anaconda_navigator\lib\site-packages (from google-auth~=2.0-&gt;databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (4.9)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in c:\anaconda_navigator\lib\site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth~=2.0-&gt;databricks-sdk&lt;1,&gt;=0.20.0-&gt;mlflow-skinny==2.19.0-&gt;mlflow) (0.4.8)
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">FunctionTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Define preprocessing pipelines</span>
<span class="n">numeric_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;onehot&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Create the pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span>  <span class="c1"># Additional MinMaxScaler step</span>
    <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MLFLOW_TRACKING_USERNAME&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;monimithra&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MLFLOW_TRACKING_PASSWORD&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;4dfd0dd546f9714f661d33b37d48dcaead2fd47f&quot;</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="c1"># Cross-validation (3/10 folds)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Train on the entire training set</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Evaluate on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c1"># Log parameters, metrics, and artifacts to MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Preprocessing&quot;</span><span class="p">,</span> <span class="s2">&quot;StandardScaler, MinMaxScaler, LogTransformation, OneHotEncoding&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;CV F1-Score Std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>

    <span class="c1"># Log the model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&quot;Logistic Regression Pipeline&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment completed and logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:45:38 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction&#39; does not exist. Creating a new experiment.
2024/12/19 22:45:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run lyrical-stork-864 at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/0/runs/91eb6e4d99b4421ca55bd049a3d76cdb
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/0
Experiment completed and logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Experiment #2: Create a pipeline for preprocessing and use LogisticRegression, RidgeClassifier, RandomForestClassifier, and XGBClassifier. Log results in MLFlow on DagsHub.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Define preprocessing pipelines</span>
<span class="n">numeric_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;onehot&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Define classifiers</span>
<span class="n">classifiers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="n">RidgeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Experiment #2&quot;</span><span class="p">)</span>

<span class="c1"># Loop through classifiers</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="n">name</span><span class="p">):</span>
        <span class="c1"># Create pipeline</span>
        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span>  <span class="c1"># Additional scaling step</span>
            <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="p">])</span>
        
        <span class="c1"># Cross-validation (10 folds)</span>
        <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
        
        <span class="c1"># Train on the entire training set</span>
        <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        
        <span class="c1"># Evaluate on the test set</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        
        <span class="c1"># Log parameters, metrics, and model</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;CV F1-Score Std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> Pipeline&quot;</span><span class="p">)</span>
        
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment #2 completed and logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:49:01 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Experiment #2&#39; does not exist. Creating a new experiment.
2024/12/19 22:49:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Logistic Regression at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1/runs/2477411d50e3434ba0e390278e17f601
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:49:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Ridge Classifier at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1/runs/b16d663fa942472e96c8df8dabc28167
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:49:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Random Forest at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1/runs/3d6063463891497280cbb429985df6a8
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:57] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:58] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:58] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:58] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
C:\Anaconda_Navigator\Lib\site-packages\xgboost\core.py:158: UserWarning: [22:49:58] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { &quot;use_label_encoder&quot; } are not used.

  warnings.warn(smsg, UserWarning)
2024/12/19 22:50:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run XGBoost at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1/runs/3e45e84f5b094f11864475394e8fbd83
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/1
Experiment #2 completed and logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Experiment #3: Perform feature engineering and attribute combination. Log results in MLFlow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Feature engineering</span>
<span class="c1"># Add new features: interaction terms and polynomial features</span>
<span class="n">numeric_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;onehot&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Experiment #3&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Engineering and Attribute Combination&quot;</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="c1"># Cross-validation (10 folds)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Train on the entire training set</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Evaluate on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    
    <span class="c1"># Log parameters, metrics, and model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Feature Engineering&quot;</span><span class="p">,</span> <span class="s2">&quot;PolynomialFeatures (degree=2), Interaction terms&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;CV F1-Score Std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&quot;Feature Engineering Pipeline&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment #3 completed and logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:53:27 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Experiment #3&#39; does not exist. Creating a new experiment.
2024/12/19 22:53:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Feature Engineering and Attribute Combination at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/2/runs/ac3db1c6b01743d88a798be6758f278e
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/2
Experiment #3 completed and logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Experiment #4: Perform feature selection using Correlation Threshold, Feature Importance, and Variance Threshold. Log results in MLFlow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># 1. Feature Selection: Correlation Threshold</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">high_correlation_pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">)</span> <span class="k">for</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span> <span class="k">for</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span>
    <span class="k">if</span> <span class="n">col1</span> <span class="o">!=</span> <span class="n">col2</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.75</span>
<span class="p">]</span>

<span class="n">features_to_drop_corr</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">col2</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">high_correlation_pairs</span><span class="p">])</span>
<span class="n">X_train_corr_filtered</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">features_to_drop_corr</span><span class="p">),</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">X_test_corr_filtered</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">features_to_drop_corr</span><span class="p">),</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># 2. Feature Selection: Variance Threshold</span>
<span class="n">var_thresh_selector</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">X_train_var_filtered</span> <span class="o">=</span> <span class="n">var_thresh_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_corr_filtered</span><span class="p">)</span>
<span class="n">X_test_var_filtered</span> <span class="o">=</span> <span class="n">var_thresh_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_corr_filtered</span><span class="p">)</span>

<span class="c1"># 3. Feature Selection: Feature Importance (Random Forest)</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_var_filtered</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">feature_importances</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">important_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">importance</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_train_corr_filtered</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">feature_importances</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">importance</span> <span class="o">&gt;</span> <span class="mf">0.01</span>
<span class="p">]</span>

<span class="n">X_train_final</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_var_filtered</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">important_features</span><span class="p">)</span>
<span class="n">X_test_final</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test_var_filtered</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">important_features</span><span class="p">)</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Experiment #4&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Selection&quot;</span><span class="p">):</span>
    <span class="c1"># Train model with selected features</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_final</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Cross-validation</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_final</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Evaluate on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_final</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    
    <span class="c1"># Log results in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Feature Selection Methods&quot;</span><span class="p">,</span> <span class="s2">&quot;Correlation Threshold, Variance Threshold, Feature Importance&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Selected Features&quot;</span><span class="p">,</span> <span class="n">important_features</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;CV F1-Score Std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;Feature Selection Model&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment #4 completed and logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:56:12 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Experiment #4&#39; does not exist. Creating a new experiment.
2024/12/19 22:56:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Feature Selection at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/3/runs/7cbc614ee68848158c318e9d405faa22
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/3
Experiment #4 completed and logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Experiment #5: Use PCA for dimensionality reduction on all the features. Create a scree plot to show which components will be selected for classification. Log results in MLFlow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Standardize the data before applying PCA</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Apply PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># Scree plot to show explained variance ratio</span>
<span class="n">explained_variance</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scree Plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Choose the number of components that explain 95% of the variance</span>
<span class="n">n_components</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.95</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">X_train_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_test_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Experiment #5&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;PCA Dimensionality Reduction&quot;</span><span class="p">):</span>
    <span class="c1"># Train Logistic Regression on PCA-transformed data</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reduced</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Cross-validation</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_reduced</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Evaluate on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    
    <span class="c1"># Log results in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;PCA Components&quot;</span><span class="p">,</span> <span class="n">n_components</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;CV F1-Score Std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;PCA Model&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PCA Experiment completed with </span><span class="si">{</span><span class="n">n_components</span><span class="si">}</span><span class="s2"> components. Results logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/de9b212d36bf974846d033241700bdf8ff838602ddafa0a569e4ebee869983aa.png" src="../_images/de9b212d36bf974846d033241700bdf8ff838602ddafa0a569e4ebee869983aa.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 22:58:19 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Experiment #5&#39; does not exist. Creating a new experiment.
2024/12/19 22:58:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run PCA Dimensionality Reduction at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/4/runs/57bb89448f684a5b88b6826a19888f7f
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/4
PCA Experiment completed with 11 components. Results logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Experiment #6: Design and execute a custom experiment. Log results in MLFlow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>  <span class="c1"># Install with `pip install imbalanced-learn`</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Apply SMOTE to balance the dataset</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train_balanced</span><span class="p">,</span> <span class="n">y_train_balanced</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Experiment #6&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Custom Experiment with SMOTE and Gradient Boosting&quot;</span><span class="p">):</span>
    <span class="c1"># Train Gradient Boosting Classifier</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_balanced</span><span class="p">,</span> <span class="n">y_train_balanced</span><span class="p">)</span>
    
    <span class="c1"># Cross-validation</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_balanced</span><span class="p">,</span> <span class="n">y_train_balanced</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Evaluate on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    
    <span class="c1"># Log results in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Oversampling Method&quot;</span><span class="p">,</span> <span class="s2">&quot;SMOTE&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;Gradient Boosting Classifier&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;CV F1-Score Std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;SMOTE and Gradient Boosting Model&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Custom Experiment #6 completed and logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:17:46 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Experiment #6&#39; does not exist. Creating a new experiment.
2024/12/19 23:18:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Custom Experiment with SMOTE and Gradient Boosting at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/5/runs/5e9b42555e01422cb7ef92d816c03286
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/5
Custom Experiment #6 completed and logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Experiment #7: Design and execute another custom experiment. Log results in MLFlow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Experiment #7&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Custom Experiment with k-NN and Hyperparameter Tuning&quot;</span><span class="p">):</span>
    <span class="c1"># Set up k-NN with GridSearchCV</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">]}</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Train the model with hyperparameter tuning</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Best parameters and best model</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
    
    <span class="c1"># Evaluate the best model on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    
    <span class="c1"># Log results in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Hyperparameters&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;k-Nearest Neighbors (k-NN)&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Best CV F1-Score&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Positives&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;True Positives&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="s2">&quot;k-NN Best Model&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Custom Experiment #7 completed and logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:20:59 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Experiment #7&#39; does not exist. Creating a new experiment.
2024/12/19 23:21:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Custom Experiment with k-NN and Hyperparameter Tuning at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/6/runs/2a839d5d9ccb4177855abac81fce1fc0
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/6
Custom Experiment #7 completed and logged to MLFlow.
</pre></div>
</div>
</div>
</div>
<p>Create meaningful F1-score plots to compare experiments and determine the best model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>  <span class="c1"># Install with `pip install imbalanced-learn`</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Set up MLFlow for logging</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/monimithra/heart_attack_pred_final.mlflow&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Heart Attack Prediction Combined Experiments&quot;</span><span class="p">)</span>

<span class="c1"># Store results for comparison</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Experiment 1: Logistic Regression</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Logistic Regression&quot;</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;Experiment&quot;</span><span class="p">:</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">,</span> <span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">),</span> <span class="s2">&quot;Test F1-Score&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">})</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">)</span>

<span class="c1"># Experiment 2: Random Forest</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;Experiment&quot;</span><span class="p">:</span> <span class="s2">&quot;Random Forest&quot;</span><span class="p">,</span> <span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">),</span> <span class="s2">&quot;Test F1-Score&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">})</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;Random Forest&quot;</span><span class="p">)</span>

<span class="c1"># Experiment 3: Feature Engineering (Gradient Boosting + SMOTE)</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Feature Engineering with SMOTE&quot;</span><span class="p">):</span>
    <span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">X_train_balanced</span><span class="p">,</span> <span class="n">y_train_balanced</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_balanced</span><span class="p">,</span> <span class="n">y_train_balanced</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_balanced</span><span class="p">,</span> <span class="n">y_train_balanced</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;Experiment&quot;</span><span class="p">:</span> <span class="s2">&quot;SMOTE + Gradient Boosting&quot;</span><span class="p">,</span> <span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">),</span> <span class="s2">&quot;Test F1-Score&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">})</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;SMOTE + Gradient Boosting&quot;</span><span class="p">)</span>

<span class="c1"># Experiment 4: PCA + Logistic Regression</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;PCA&quot;</span><span class="p">):</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
    <span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;Experiment&quot;</span><span class="p">:</span> <span class="s2">&quot;PCA + Logistic Regression&quot;</span><span class="p">,</span> <span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">),</span> <span class="s2">&quot;Test F1-Score&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">})</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">))</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;PCA + Logistic Regression&quot;</span><span class="p">)</span>

<span class="c1"># Experiment 5: k-NN + Hyperparameter Tuning</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;k-NN with Hyperparameter Tuning&quot;</span><span class="p">):</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">]}</span>
    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;Experiment&quot;</span><span class="p">:</span> <span class="s2">&quot;k-NN (Tuned)&quot;</span><span class="p">,</span> <span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">:</span> <span class="n">cv_scores</span><span class="p">,</span> <span class="s2">&quot;Test F1-Score&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">})</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="s2">&quot;k-NN Best Model&quot;</span><span class="p">)</span>

<span class="c1"># Plot F1-score comparison</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="c1"># Plot Mean CV F1-Score</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s2">&quot;Experiment&quot;</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score Comparison Across Experiments&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Experiment&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean CV F1-Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot Test F1-Score</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s2">&quot;Experiment&quot;</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test F1-Score Comparison Across Experiments&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Experiment&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Test F1-Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:25:14 INFO mlflow.tracking.fluent: Experiment with name &#39;Heart Attack Prediction Combined Experiments&#39; does not exist. Creating a new experiment.
2024/12/19 23:25:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Logistic Regression at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7/runs/04889f1070a740939ea5275efee98cf2
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:25:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Random Forest at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7/runs/d9d1ba688425420b99e74cce8779ba27
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:26:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run Feature Engineering with SMOTE at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7/runs/87cc372d4a7746d4a579af4249edd474
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:26:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run PCA at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7/runs/7522045f58fa4fae801da2a01614fdef
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/19 23:26:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🏃 View run k-NN with Hyperparameter Tuning at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7/runs/7fedc035044d471f82f8c8dc1966147b
🧪 View experiment at: https://dagshub.com/monimithra/heart_attack_pred_final.mlflow/#/experiments/7
</pre></div>
</div>
<img alt="../_images/afe37fd7ed537587d00bf86fe1669d47e1ee74ad4bb6c8c5bc8c029ca2fabe1f.png" src="../_images/afe37fd7ed537587d00bf86fe1669d47e1ee74ad4bb6c8c5bc8c029ca2fabe1f.png" />
<img alt="../_images/7d2070046361e6bad5d40efda569332eb19e62e8f4ccbe062668182f08235e42.png" src="../_images/7d2070046361e6bad5d40efda569332eb19e62e8f4ccbe062668182f08235e42.png" />
</div>
</div>
<p>Save the final model using joblib.
Create a FastAPI application to serve the model.
Containerize the FastAPI application using Docker and push to Docker Hub.
Deploy the containerized API to a cloud platform.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Load the cleaned dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;cleaned_heart_data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Apply PCA for dimensionality reduction</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># Retain 95% variance</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># Train Logistic Regression model</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Save the PCA, scaler, and model using joblib</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="s2">&quot;scaler.joblib&quot;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pca</span><span class="p">,</span> <span class="s2">&quot;pca.joblib&quot;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">final_model</span><span class="p">,</span> <span class="s2">&quot;final_model_pca_lr.joblib&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final PCA + Logistic Regression model saved as &#39;final_model_pca_lr.joblib&#39;.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scaler and PCA components saved as &#39;scaler.joblib&#39; and &#39;pca.joblib&#39;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final PCA + Logistic Regression model saved as &#39;final_model_pca_lr.joblib&#39;.
Scaler and PCA components saved as &#39;scaler.joblib&#39; and &#39;pca.joblib&#39;.
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Intro &amp; Links</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>